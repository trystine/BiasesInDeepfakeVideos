### Inorder to analyze the gender bias in deep fake videos we have trained a deep learning model that classifies a video based on the gender. 

### The aim is to analyze the number of females and males videos correctly predicted and those which are misclassified we have studied their features and observed that it classifies based on stereotypical features of the deepfake videos.
### For training purpose and building the classification model, we have considered 500 videos from the 1000 videos of Deepfakes. 

### Based on these videos we built our classification model that classifies a video being male and female.</b>

### Experimented algorithms like LSTM, Simple RNN, GRU and CNN. Out of all of these algorithms CNN works the best. Hence going forward with it to actually train our model and find anomalies based on classification.

### We have studied how algorithmic bias exist based on the dataset bias and classifies few of the deepfake videos of females being classified as male because of their short hair.

### This highlights the gender bias in the deepfake videos.
